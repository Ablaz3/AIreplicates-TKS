{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9df0c7e",
   "metadata": {},
   "source": [
    "This will be a notebook to go along with what Karpathy does in his project. link: https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing#scrollTo=h5hjCcLDr2WC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "955ead58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-10 16:49:28--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8000::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: 'input.txt.1'\n",
      "\n",
      "input.txt.1         100%[===================>]   1.06M  3.57MB/s    in 0.3s    \n",
      "\n",
      "2023-04-10 16:49:29 (3.57 MB/s) - 'input.txt.1' saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get dataset\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aef80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the dataset and inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1754ef62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "#finding the length of the dataset in characters?\n",
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691ce5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#look at the first 1000 characters in the dataset\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed1e69c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ! $ & ' , - . 3 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "#all unique characters in the text, and covabulary size\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(' '.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a69f240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 63, 1, 58, 46, 43, 56, 43, 2]\n",
      "Hey there!\n"
     ]
    }
   ],
   "source": [
    "#create a mapping from words to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars)} #dictionary comprehension. i takes value of index of the character in chars, while ch takes value of character itself. Creates a vocab for these two\n",
    "itos = { i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] #takes string, and outputs the encoded list of integers\n",
    "decode = lambda l: ''.join([itos[c] for c in l]) #takes a list of integers, and outputs the decoded words\n",
    "\n",
    "\n",
    "print(encode(\"Hey there!\"))\n",
    "print(decode(encode(\"Hey there!\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2456a867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "#now storing the entire text dataset in a torch.tensor\n",
    "import torch #pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a7db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate dataset into training and validation sets\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n] #first 90% for training\n",
    "val_data = data[n:] #last 10% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29380468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define how large parts of the data our model will be receiving (max) when it's deciding the next output\n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a00911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target is: 47\n",
      "when input is tensor([18, 47]) the target is: 56\n",
      "when input is tensor([18, 47, 56]) the target is: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target is: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target is: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target is: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is: 58\n"
     ]
    }
   ],
   "source": [
    "#show what the context and target will be for the above input\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b0a8db",
   "metadata": {},
   "source": [
    "get_batch below is a function that returns two tensors of dimensions 4x8. The 4 is because we will process 4 inputs simultaneously, while the 8 is the batch size. The first tensor consists of the inputs, while the second consists of the corresponding targets.\n",
    "We then call the function, and create a nested for loop to demonstrate what the funciton does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d403ee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      " torch.Size([4, 8]) \n",
      " tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets: \n",
      " torch.Size([4, 8]) n tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "when input is [24], target is 43\n",
      "when input is [24, 43], target is 58\n",
      "when input is [24, 43, 58], target is 5\n",
      "when input is [24, 43, 58, 5], target is 57\n",
      "when input is [24, 43, 58, 5, 57], target is 1\n",
      "when input is [24, 43, 58, 5, 57, 1], target is 46\n",
      "when input is [24, 43, 58, 5, 57, 1, 46], target is 43\n",
      "when input is [24, 43, 58, 5, 57, 1, 46, 43], target is 39\n",
      "when input is [44], target is 53\n",
      "when input is [44, 53], target is 56\n",
      "when input is [44, 53, 56], target is 1\n",
      "when input is [44, 53, 56, 1], target is 58\n",
      "when input is [44, 53, 56, 1, 58], target is 46\n",
      "when input is [44, 53, 56, 1, 58, 46], target is 39\n",
      "when input is [44, 53, 56, 1, 58, 46, 39], target is 58\n",
      "when input is [44, 53, 56, 1, 58, 46, 39, 58], target is 1\n",
      "when input is [52], target is 58\n",
      "when input is [52, 58], target is 1\n",
      "when input is [52, 58, 1], target is 58\n",
      "when input is [52, 58, 1, 58], target is 46\n",
      "when input is [52, 58, 1, 58, 46], target is 39\n",
      "when input is [52, 58, 1, 58, 46, 39], target is 58\n",
      "when input is [52, 58, 1, 58, 46, 39, 58], target is 1\n",
      "when input is [52, 58, 1, 58, 46, 39, 58, 1], target is 46\n",
      "when input is [25], target is 17\n",
      "when input is [25, 17], target is 27\n",
      "when input is [25, 17, 27], target is 10\n",
      "when input is [25, 17, 27, 10], target is 0\n",
      "when input is [25, 17, 27, 10, 0], target is 21\n",
      "when input is [25, 17, 27, 10, 0, 21], target is 1\n",
      "when input is [25, 17, 27, 10, 0, 21, 1], target is 54\n",
      "when input is [25, 17, 27, 10, 0, 21, 1, 54], target is 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337) #to get same results as Andrej\n",
    "batch_size = 4 #how many sequences to process in paralell\n",
    "block_size = 8 #max context length\n",
    "\n",
    "def get_batch(split):\n",
    "    #will return two tensors of dimensions 4x8\n",
    "    data = train_data if split=='train' else val_data\n",
    "    #generate (batch_size) amount of random intervals in data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) #generate 4 random indices in the data\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) #will be the inputs\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix]) #targets for inputs x\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:', '\\n', xb.shape, '\\n', xb)\n",
    "print('targets:', '\\n', yb.shape, 'n', yb)\n",
    "\n",
    "for i in range(batch_size): #the batch we're on\n",
    "    for j in range(block_size): #the point in time in the sequence\n",
    "        context = xb[i, :j+1] \n",
    "        target = yb[i,j]\n",
    "        print(f\"when input is {context.tolist()}, target is {target.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0aaba",
   "metadata": {},
   "source": [
    "We will now create a simple language model, only taking context of block_size 1, and only predicting the next letter per run through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a25ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape:  torch.Size([32, 65])\n",
      "Loss:  tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module): #define the bigramlanguagemodel class as a subclass of the nn.Module superclass\n",
    "    def __init__(self, vocab_size):\n",
    "        #allow us to use any nn.Module methods and properties\n",
    "        super().__init__() \n",
    "        # create a lookup table where each input gets it's own row, and can read off the logits for the next token\n",
    "        # each character has one row, and each value in this row represents the probability of some character\n",
    "        # coming next. 65 x 65 means each character has a value for each other character\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) \n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        # arrange the vocab_size X vocab_size table into (B, T, C) dimensions. \n",
    "        # B = batch_size = 4\n",
    "        # T = time or block_size = 8\n",
    "        # c = channels = vocab_size = 65\n",
    "        # This table in other words contains the predicted probabilities of the next character \n",
    "        # for each respective character input\n",
    "        logits = self.token_embedding_table(idx) \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            #if targets are input, calculate loss:\n",
    "            #F.cross_entropy expects channel as the second parameter, so we turn \n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            #f.cross_entropy first sotftmaxes the logits, then compares it, the predicted probabilities,\n",
    "            #to the true probabilities of targets through a negative log-likelihood loss \n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        #generate max_new_tokens new characters at the end of idx, which is a (B, T) tensor\n",
    "        for _ in range(max_new_tokens):\n",
    "            #run forward to get predictions\n",
    "            logits, loss = self(idx)  #in a nn.Module, calling the tensor itself calls the forward() method\n",
    "            # focus only on last time step\n",
    "            logits = logits[:, -1 ,:] #T dimension is then 1, so the tensor is (B, C)\n",
    "            # apply softmax for probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # dimensions (B, 1)\n",
    "            #concatenate the sequence with the prediction, in effect appending the prediction\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(\"Logits shape: \", logits.shape)\n",
    "print(\"Loss: \", loss)\n",
    " \n",
    "idx = torch.zeros((1, 1), dtype=torch.long) #B=1, T=1. This is a small array we can use to test generate. \n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f187ca",
   "metadata": {},
   "source": [
    "Now we are going to train the model by first defining an optimizer for the model's parameters, and then updating values in the lokoup table a certain amount of times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4da3406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the optimizer.\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3) #learning rate = 1e-3 -> 1*10^(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87560b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.721843719482422\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 #try a higher batch size\n",
    "for steps in range(1000): #update 100 times\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train') #as per the previous function, xb will be the context, and yb will be the targets\n",
    "    \n",
    "    # evaluate the loss function\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31b4f52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create example tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337) #for reproducability\n",
    "B,T,C = 4, 8, 2 #batch = 4, time = 8, channels = 2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b32ca",
   "metadata": {},
   "source": [
    "Now our task is to let the 8 elements of the time dimension talk to each other, but only back in time. So 3 only talks to 2, 1, and 0. do to this we will find the mean of x[b,i], where i<=t, in the tensor x[b,t] this will be a basic attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9de68a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]]) \n",
      "\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "#basic bag of words implementation\n",
    "xbow = torch.zeros(B,T,C) #x, bag of words\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev =x[b,:t+1] # will be of dimensions (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0) #0 indicates that we calculate the mean along the batch dimension\n",
    "     \n",
    "print(x[0], '\\n')\n",
    "print(xbow[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd118ca",
   "metadata": {},
   "source": [
    "Notice above how the first timestep of each tensor is the same. After the first time step, the second tensor's timesteps begin to be the average of all previous of the first tensor's timesteps, so diverge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c791e",
   "metadata": {},
   "source": [
    "Showing off the concept of using matrix multiplication to get weights corresponding with row in tensor a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d39c7e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a \n",
      " tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b \n",
      " tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c \n",
      " tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "#normalize values of a by creating a tensor of the same shape as a, with the sum of values along batch axis.\n",
    "#keepdim=True\n",
    "a = a / torch.sum(a, 1, keepdim=True) #create probability distribution over a. Each row sums to 1\n",
    "b = torch.randint(10,(3,2), dtype=torch.float32)\n",
    "c = a @ b\n",
    "print('a \\n', a)\n",
    "print('b \\n', b)\n",
    "print('c \\n', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bbfa4e",
   "metadata": {},
   "source": [
    "Now creating the actual implementation of the matrix multiplication:\n",
    "wei is of dimension (T,T), while x is of dimension (B,T,C). Pytorch will create an extradimension for wei to multiply the two, b -> wei=(B, T, T). Multiplying this with X is the same procedure as shown in the last step, imagine B=1, T=3, C=2 in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61793fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create matrix of T*T, because we are going to max average over T steps, and use one set of weights for each T value\n",
    "wei = torch.tril(torch.ones(T, T)) \n",
    "wei = wei / torch.sum(wei, 1, keepdim=True)\n",
    "xbow2 = wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b1b53c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using softmax and masked to do the same process\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros(T, T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25f9e202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create example tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337) #for reproducability\n",
    "B,T,C = 4, 8, 2 #batch = 4, time = 8, channels = 2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c8f85a",
   "metadata": {},
   "source": [
    "Now our task is to let the 8 elements of the time dimension talk to each other, but only back in time. So 3 only talks to 2, 1, and 0. do to this we will find the mean of x[b,i], where i<=t, in the tensor x[b,t] this will be a basic attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70071845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]]) \n",
      "\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "#basic bag of words implementation\n",
    "xbow = torch.zeros(B,T,C) #x, bag of words\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev =x[b,:t+1] # will be of dimensions (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0) #0 indicates that we calculate the mean along the batch dimension\n",
    "     \n",
    "print(x[0], '\\n')\n",
    "print(xbow[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c5e74",
   "metadata": {},
   "source": [
    "Notice above how the first timestep of each tensor is the same. After the first time step, the second tensor's timesteps begin to be the average of all previous of the first tensor's timesteps, so diverge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ac845",
   "metadata": {},
   "source": [
    "Showing off the concept of using matrix multiplication to get weights corresponding with row in tensor a:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70470f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create matrix of T*T, because we are going to max average over T steps, and use one set of weights for each T value\n",
    "wei = torch.tril(torch.ones(T, T)) \n",
    "wei = wei / torch.sum(wei, 1, keepdim=True)\n",
    "xbow2 = wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da94209b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using softmax and masked to do the same process\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros(T, T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b83f167",
   "metadata": {},
   "source": [
    "Version 4 will use self-attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0cf7baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic set up\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 \n",
    "x = torch.randn(B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1938b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a head\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False) #no bias term\n",
    "query = nn.Linear(C, head_size, bias=False) #no bias term\n",
    "value = nn.Linear(C, head_size, bias=False) #no bias term\n",
    "k = key(x) # (B, T, Head_size) -> what the element looks for in other elements\n",
    "q = query(x) # (B, T, Head_size) -> the place query looks. Overlaps with high values are high intereste\n",
    "v = value(x) # (B, T, Head_size) -> The actual information communicated if interest is high (next block)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, Head_size) @ (B, Head_Size, T) -> (B, T, T)\n",
    "wei = wei ** head_size**-0.5 # scaling-> dividing by square root of dimension of key, which means head_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00524511",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros(T, T) -> previous implementation\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "out = wei @ v # so we compute the attention from the value query derived from x, not x itself"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
