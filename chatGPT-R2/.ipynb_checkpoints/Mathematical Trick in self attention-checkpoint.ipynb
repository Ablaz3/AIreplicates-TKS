{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "33dcf4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create example tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337) #for reproducability\n",
    "B,T,C = 4, 8, 2 #batch = 4, time = 8, channels = 2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08126c1",
   "metadata": {},
   "source": [
    "Now our task is to let the 8 elements of the time dimension talk to each other, but only back in time. So 3 only talks to 2, 1, and 0. do to this we will find the mean of x[b,i], where i<=t, in the tensor x[b,t] this will be a basic attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "68f82acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]]) \n",
      "\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "#basic bag of words implementation\n",
    "xbow = torch.zeros(B,T,C) #x, bag of words\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev =x[b,:t+1] # will be of dimensions (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0) #0 indicates that we calculate the mean along the batch dimension\n",
    "     \n",
    "print(x[0], '\\n')\n",
    "print(xbow[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d91fa57",
   "metadata": {},
   "source": [
    "Notice above how the first timestep of each tensor is the same. After the first time step, the second tensor's timesteps begin to be the average of all previous of the first tensor's timesteps, so diverge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599cec94",
   "metadata": {},
   "source": [
    "Showing off the concept of using matrix multiplication to get weights corresponding with row in tensor a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "678f7760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a \n",
      " tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b \n",
      " tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c \n",
      " tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "#normalize values of a by creating a tensor of the same shape as a, with the sum of values along batch axis.\n",
    "#keepdim=True\n",
    "a = a / torch.sum(a, 1, keepdim=True) #create probability distribution over a. Each row sums to 1\n",
    "b = torch.randint(10,(3,2), dtype=torch.float32)\n",
    "c = a @ b\n",
    "print('a \\n', a)\n",
    "print('b \\n', b)\n",
    "print('c \\n', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b1c3b",
   "metadata": {},
   "source": [
    "Now creating the actual implementation of the matrix multiplication:\n",
    "wei is of dimension (T,T), while x is of dimension (B,T,C). Pytorch will create an extradimension for wei to multiply the two, b -> wei=(B, T, T). Multiplying this with X is the same procedure as shown in the last step, imagine B=1, T=3, C=2 in the last step.\n",
    "Thus we will get xbow2 as a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8535aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create matrix of T*T, because we are going to max average over T steps, and use one set of weights for each T value\n",
    "wei = torch.tril(torch.ones(T, T)) \n",
    "wei = wei / torch.sum(wei, 1, keepdim=True)\n",
    "xbow2 = wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "60deb966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using softmax and masked to do the same process\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros(T, T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
